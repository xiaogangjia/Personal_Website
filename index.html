<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiaogang Jia</title>
  
  <meta name="author" content="Xiaogang Jia">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    /* Apply a circular mask to the image */
    .circular-image {
      width: 100px; /* Adjust the width and height as needed */
      height: 100px;
      border-radius: 50%;
      overflow: hidden;
    }

    /* Ensure the image fills the circular container */
    .circular-image img {
      width: 100%;
      height: auto;
      display: block;
    }
  </style>
  <title>Circular Image in Table</title>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiaogang Jia</name>
              </p>
              <p>I am a PhD student in the <a href="https://alr.iar.kit.edu/">Autonomous Learning Robots</a> (ALR) at the Karlsruhe Institute of Technology (KIT), Germany.
                My research focuses on robotics and machine learning supervised by <a href="https://alr.iar.kit.edu/21_65.php">Gerhard Neumann</a> and <a href="http://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a>.
              </p>

              <p style="text-align:center">
                <a href="mailto:jia266163@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_Moritz_Reuss.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=E7Tja9gAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/xiaogangjia">Github</a> &nbsp/&nbsp
<!--                <a href="https://www.linkedin.com/in/moritzreuss/?locale=en_US">LinkedIn</a>-->
              </p>
            </td>

            <td class="circular-image", style="width:20%;max-width:20%">
            <!-- Replace 'your-image.jpg' with the actual path to your image -->
            <img src="images/white.jpg" alt="Circular Image">
<!--            </td>-->
<!--            <td style="padding:2.5%;width:40%;max-width:40%">-->
<!--              <a href="images/white.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/White.jpg" class="hoverZoomLink"></a>-->
<!--            </td>-->
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My primary research goal is to build intelligent embodied agents that assist people in their everyday lives and
                communicate intuitively.
                One of the key challenges to be solved towards this goal is learning from multimodal, uncurated human demonstrations
                without rewards.
                Therefore, I am working on novel methods that exploit multimodality and learn versatile behaviour.
                Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <div style="display: flex;">
                  <div style="flex: 0 0 25%; max-width: 25%;">
                    <img src='images/d3il_compressed.gif' style="width: 100%; max-width: 100%;">
                  </div>
                  <div style="flex: 0 0 75%; max-width: 75%; padding-left: 20px;">
                    <a href="https://openreview.net/pdf?id=6pPYRXKPpw">
                      <papertitle>Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations
                      </papertitle></a>
                    <br>
                    <strong>Xiaogang Jia</strong>,
                    <a href="https://alr.anthropomatik.kit.edu/21_495.php">Denis Blessing</a>,
                    <a href="https://alr.iar.kit.edu/21_500.php">Xinkai Jiang</a>,
                    Moritz Reuss,
                    Atalay Donat,
                    <a href="http://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a> <br>,
                    <a href="https://alr.anthropomatik.kit.edu/21_65.php">Gerhard Neumann</a> <br>
                    <br>
                      ICLR 2024
                      <br>
                      <a href="https://openreview.net/pdf?id=6pPYRXKPpw">OpenReview</a>
                      <p></p>
                      <p>
                        Introducing D3IL, a novel set of simulation benchmark environments and datasets tailored for Imitation Learning,
                        D3IL is uniquely designed to challenge and evaluate AI models on their ability to learn and replicate diverse,
                        multi-modal human behaviors. Our environments encompass multiple sub-tasks and object manipulations, providing a rich
                        diversity in behavioral data, a feature often lacking in other datasets. We also introduce practical metrics to
                        effectively quantify a model's capacity to capture and reproduce this diversity. Extensive evaluations of state-of-the-art methods on D3IL offer insightful
                        benchmarks, guiding the development of future imitation learning algorithms capable of generalizing complex human
                        behaviors.
                      </p>
                  </div>
                </div>
              </td>
            </tr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="background-color: #ffffd0;">
                <td style="padding:20px;width:100%;vertical-align:middle">
                    <div style="display: flex;">
                      <div style="flex: 0 0 25%; max-width: 25%;">
                        <img src='images/beso_kitchen.gif' style="width: 100%; max-width: 100%;">
                      </div>
                        <div style="flex: 0 0 75%; max-width: 75%; padding-left: 20px;">
                            <a href="https://intuitive-robots.github.io/beso-website">
                                <papertitle>Goal Conditioned Imitation Learning using Score-based Diffusion Policies</papertitle>
                            </a>
                            <br>
                            Moritz Reuss,
                            <a href="https://irl.anthropomatik.kit.edu/21_67.php">Maximilian Li</a>,
                            <strong>Xiaogang Jia</strong>,
                            <a href="http://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a> <br>
                            <br>
                            <em><span style="color:red; font-weight:bold;">Best Paper Award</span> @ Workshop on Learning from Diverse, Offline Data
                              (L-DOD) @ ICRA 2023, Robotics: Science and Systems (RSS)</em>, 2023

                            <br>
                            <a href="https://intuitive-robots.github.io/beso-website">project page</a> 
                            /
                            <a href="https://github.com/intuitive-robots/beso">Code </a>
                            /
                            <a href="https://arxiv.org/pdf/2304.02532">arXiv</a>
                            <p></p>
                            <p>
                            We present a novel policy representation, called BESO, for goal-conditioned imitation learning using score-based diffusion models.
                            BESO is able to effectively learn goal-directed, multi-modal behavior from uncurated reward-free offline-data.
                            On several challening benchmarks our method outperforms current policy representation by a wide margin. 
                            BESO can also be used as a standard policy for imitation learning and achieves state-of-the-art performance
                            with only 3 denoising steps. 
                            </p>
                        </div>
                    </div>
                </td>
            </tr>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <div style="display: flex;">
                  <div style="flex: 0 0 25%; max-width: 25%;">
                    <img src='images/IMC_obstacle_avoidance.png' style="width: 100%; max-width: 100%;">
                  </div>
                  <div style="flex: 0 0 75%; max-width: 75%; padding-left: 20px;">
                    <a href="https://arxiv.org/pdf/2303.15349">
                      <papertitle>Information Maximizing Curriculum: A Curriculum-Based Approach for Learning Versatile Skills
                      </papertitle>
                    </a>
                    <br>
                    <a href="https://alr.anthropomatik.kit.edu/21_495.php">Denis Blessing</a>,
                    <a href="https://alr.anthropomatik.kit.edu/21_69.php">Onur Celik</a>,
                    <strong>Xiaogang Jia</strong>,
                    Moritz Reuss,
                    <a href="https://irl.anthropomatik.kit.edu/21_67.php">Maximilian Xiling</a>,
                    <a href="http://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a> <br>,
                    <a href="https://alr.anthropomatik.kit.edu/21_65.php">Gerhard Neumann</a> <br>
                    <br>
                    <em>Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) </em>, 2023
                    <br>
                    <a href="https://arxiv.org/pdf/2303.15349">arXiv</a>
                    <p></p>
                    <p>
                      We introduce the Information Maximizing Curriculum method to address mode-averaging in imitation learning by enabling
                      the model to specialize in representable data. This approach is enhanced by a mixture of experts (MoE) policy, each
                      focusing on different data subsets, and employs a unique maximum entropy-based objective for full dataset coverage.
                      </p>
              </td>
            </tr>
            <tr style="background-color: #ffffd0;">
            </tr>


</tbody>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
      <td style="padding:0px; vertical-align: middle;">
          <br>
          <p style="text-align:right;font-size:small;">
              The website is based on the code from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>!
          </p>
      </td>
  </tr>
</tbody></table>
</body>

</html>
